# This program creates different classifiers (Random Forest, KNN, SVC, MLP, and Gaussian NB), compares them to each other to see which model is superior.
# The goal is to determine which ML model is able to draw strong correlations between the paired predictors that contribute to CDR scores in patients with AD.

# Set X (predictors) and y (outcome)
X = new_df[['Age', 'Educ', 'SES', 'MMSE', 'nWBV']]
y = new_df['CDR Y/N']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

clf = RandomForestClassifier(n_estimators=200, random_state=12)
clf.fit(X_train, y_train)

# Check shape/dimensions of the training and the testing sets
X_train.shape
X_test.shape

predicted = clf.predict(X_test)
expected = y_test

print('The accuracy is ', f'{clf.score(X_test, y_test):.2%}')

# Create a loop that takes 2 columns at a time to determine the accuracy (in classifier)
base_path = 'C:/Users/augustina/Documents/AlzheimerProj'
file_path = base_path + 'AD_w_YN_CDR.csv'
diff_df = pd.read_csv(file_path)

# Creates a list from the headers in the dataset and performs pairwise matching without duplicates.
header_list = new_df.columns[:-1]  # remove the CDR column to create feature pairs
# print(header_list)
pair_order = itertools.combinations(header_list, 2)

num = 0
feature_list = list(pair_order)

# Iterates through list of column pairs, creating a separate csv for each one (to then be run through model below).
for i in feature_list:
    two_col_df = diff_df[[i[0],i[1]]].copy()
    version_num = str(num)
    tail = 'updated_col_{}.csv'.format(version_num)
    path = base_path + str(tail)
    two_col_df.to_csv(path)
    num += 1
print('28 FILES SAVED')

j = 0
accur_list = []
clf = RandomForestClassifier(n_estimators=200, random_state=12)
y = diff_df['CDR Y/N']

while j < 15:
    tail = 'updated_col_{}.csv'.format(j)
    path = base_path + str(tail)
    two_col_df = pd.read_csv(path)
    X_train, X_test, y_train, y_test = train_test_split(two_col_df, y, random_state=12, test_size=0.2)
    clf.fit(X_train, y_train)
    y_predicted = clf.predict(X_test)
    accuracy_score = clf.score(X_test, y_test)
    accur_list.append(accuracy_score)
    print(f"The accuracy for the feature combination of {feature_list[j][0]} and {feature_list[j][1]} is "
          f"{accuracy_score}")
    j += 1

# print(accur_list)

# This loop iterates through items in the estimators' dictionary. For each key-value pair, it unpacks the key into
# estimator_name and value into estimator_object.
estimators = {"KNN": KNeighborsClassifier(n_neighbors=11),
              "SVC": SVC(kernel='rbf', gamma='scale'),
              "GaussianNB": GaussianNB(),
              "RandomForest": RandomForestClassifier(max_depth=None, min_samples_leaf=1,
                                          min_samples_split=2, n_estimators=50, random_state=12),
              "MLP": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=2)}

# For loop iterates through each csv file and runs each model/estimator over each combination pair.
for estimator_name, estimator_object in estimators.items():
    j=0
    while j < 15:
        tail = 'updated_col_{}.csv'.format(j)
        path = base_path + str(tail)
        two_col_df = pd.read_csv(path)

        X_train, X_test, y_train, y_test = train_test_split(two_col_df, y, random_state=12, test_size=0.2)
        kfold = KFold(n_splits=5, random_state=42, shuffle=True) # changed fold to 5
        scores = cross_val_score(estimator=estimator_object, X=two_col_df, y=y, cv=kfold)

        print(f"{estimator_name:>25}: " + f"mean accuracy={scores.mean():.2%}; " + f"std={scores.std():.2%}." +
              f"For the feature combinations of {feature_list[j][0]} and {feature_list[j][1]}.")
        j += 1


#  Tuning RF
#Made decision to tune all 6 features at once instead of each individual combination. This decision was made knowing there would be a trade off between efficieny and accuracy
rf_classifier = RandomForestClassifier(n_estimators = 100, random_state = 12)
#define the parameter grid for hyperparamter tuning
param_grid = {
    'n_estimators':[50,100,200],
    'max_depth':[None,5,10],
    'min_samples_split':[2,5,10],
    'min_samples_leaf':[1,2,4]
}

# Create GridSearchCV object for hyperparameter tuning.
grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=kfold)

# Perform hyperparameter tuning.
grid_search.fit(df_noCDR, target)

# Get the best parameters and best score.
best_params = grid_search.best_params_
best_score = grid_search.best_score_

# Print the best parameters and best score.
print("Best Parameters: ", best_params)
print("Best Score: {:.2f}%".format(best_score * 100))

# K-Fold cross-validation (using 5-fold cv)
kfold = KFold(n_splits=5, random_state=12, shuffle=True)
rf_classifier = RandomForestClassifier(n_estimators = 100, random_state = 12)


#Cross validation for our Random Forest model using hyper-parameters from above tuning.
j = 0
validation_lst = []
rf_classifier = RandomForestClassifier(n_estimators = 50, max_depth = 5, min_samples_leaf = 1, 
                                       min_samples_split = 5, random_state = 12)
target = new_df['CDR Y/N']

while j < 15:
    tail = 'updated_columns_{}.csv'.format(j)
    path = os.path.join(base_path,tail)
    two_column_df = pd.read_csv(path)
    scores = cross_val_score(estimator=rf_classifier, X=two_column_df, y=target, cv=kfold)
    avg = scores.mean()
    validation_lst.append(avg)
    stdev = scores.std()
    print("The mean for the feature combination of {} and {} is {:.2%}.\n".format(combos[j][0], combos[j][1],
                                                                                   avg))
    #print("The stdeviation for the feature combination of {} and {} is {:.2%}.".format(combos[j][0], combos[j][1],
                                                                                  # stdev))
    j+=1


# Plot accuracies
y = ['M/F & Age','M/F & Educ', 'M/F & SES','M/F & MMSE','M/F & nWBV', 'Age & Educ','Age & SES',
    'Age & MMSE', 'Age & nWBV', 'Educ & SES', 'Educ & MMSE', 'Educ & nWBV', 'MMSE & SES', 'nWBV & SES',
    'MMSE & nWBV']

plt.barh(y, validation_lst,color='mediumaquamarine')
plt.title("Mean accuracies for the cross validation")
plt.xlabel("Mean accuracy")
plt.ylabel("Feature Combinations")
plt.show()


# Creates a list with headers in it.
header_list = list(new_df)

# Visualizing Random Forest: Tree plot
# Creates image containing 5 decision trees. Saves image to PythonProjects folder.
fn = header_list[:-1]
cn = ['No', 'Yes']
fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(10, 2), dpi=3000)
for index in range(0, 5):
    tree.plot_tree(clf.estimators_[index],
                   feature_names=fn,
                   class_names=cn,
                   filled=True,
                   ax=axes[index])

    axes[index].set_title('Decision Tree: ' + str(index), fontsize=11)
fig.savefig('clf_5_trees_Image_.png')

# Creates figure containing an individual decision tree. Saves image to PythonProjects folder.
fn = header_list[:-1]
cn = ['No', 'Yes']
fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(4, 4), dpi=800)
tree.plot_tree(clf.estimators_[0],
               feature_names=fn,
               class_names=cn,
               filled=True)
fig.savefig('clf_individual_tree_Image_.png')
